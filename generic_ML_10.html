<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
	This is an example of a sub page for each module.  It has to be replicated in each module, containing the requested contents -  artefacts, notes, reflections etc
	Ensure you give a different title to each replica and link it to the main module page accordingly.
-->
<html>
	<head>
		<title>Tasweem Beelunkhan</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="css/main.css" />
		<noscript><link rel="stylesheet" href="css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo"><span>Tasweem Beelunkhan</span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="About.html">About Me</a></li>
							<li><a href="Launch Module.html">The Data Professional</a></li>
							<li><a href="Module 2.html">Numerical Analysis</a></li>
							<li><a href="Module 4.html">Deciphering Big Data</a></li>
							<li><a href="Module 3.html">Visualising Data</a></li>
							<li><a href="Module 5.html">Machine Learning</a></li>
							<li><a href="Module 6.html">Research Methods and Professional Practice</a></li>
							<li><a href="Project.html">Project</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main" class="alt">

						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h1> &#10021; Unit 10: CNN Interactive Learning </h1>
										<h3>Outcomes from the Team Exercises and activites</h3>
									</header>

											<p>Deep learning's fast advancements have piqued the interest of both students and practitioners. Despite its promise, beginners are typically intimidated by its inherent intricacy. To address this, the authors Wang., et al, 2021 provide the "CNN EXPLAINER," an interactive application meant to help beginners understand convolutional neural networks (CNNs).</p>
											
											<p>The instrument was designed in response to problems highlighted during interviews with teachers and student surveys. CNN EXPLAINER provides an integrated model overview that concisely summarises the structure of a CNN. It provides dynamic visual explanations to assist people understand the underlying CNN components. The tool enables users to comprehend the connection between fundamental mathematical operations and overarching model structures by facilitating seamless transitions between various abstraction levels.</p>
											
											<p>CNN EXPLAINER illustrates how CNNs transform input photos into categorization predictions. It explains how convolutional layers work using three integrated perspectives, each of which delves further into the convolutional process. The tool seeks to make CNNs more approachable by providing anything from a broad overview of the CNN architecture to deep insights into mathematical processes.</p>


									       <h3 style="color: #CFA7F6;">Seminar Activity on Image Recognition with CNN:</h3>


											<h3>Objective</h3>
											<p>Undertake image recognition activities at different layers (reLU, intermediate, etc.). Upload your own image (using similar images - e.g., a car or a teacup - as well as dissimilar images) and test how the CNN can detect objects similar to trained image objects.</p>
											
											<h3>Image Testing</h3>
											<p>Using the CIFAR10-trained model, we evaluated its performance on two external images: an airplane (present in the CIFAR10 labels) and a hat (absent from the CIFAR10 dataset).</p>
											<img src="images/ML_Unit10_P1.png" alt="Airplane Image">
											<img src="images/ML_Unit10_P2.png" alt="Hat Image">
											<p>Upon testing, the model adeptly identified the airplane, showcasing its capability to generalize effectively on familiar categories. Conversely, when presented with the hat, the model faltered, underscoring the limitations tied to its training data. This highlights the importance of having diverse training data when expecting a model to recognize a broader array of objects.</p>
											
											<h3>Visualization of Activations</h3>
											<p>To see the image recognition activities at different layers, particularly focusing on the activations produced by layers like ReLU, we need to visualize the intermediate outputs of the layers in the Convolutional Neural Network (CNN). This will give insight into what features the network is learning at various depths.</p>
											<p>The steps are as follows:</p>
											<ul>
											    <li>Layer Selection: Identification of particular layers, with a focus on those utilising ReLU activations, laying the groundwork for thorough visualisation.</li>
											    <li>Construction of an Activation Model: Using the Keras framework, a specialised model was built to explicate the intermediate activations, offering a greater understanding of layer-wise processing.</li>
											    <li>Image Processing: To ensure best compatibility with the model, a thorough preparation strategy was used on the input image, covering critical stages such as scaling, normalisation, and reshaping.</li>
											    <li>Activation Generation: Using the model and the processed picture, this phase required collecting intermediate outputs that revealed the complex transformations that the image goes through.</li>
											    <li>Visualisation: As the approach's culmination, this stage involves charting the resultant activations, providing a deep insight into the model's fundamental cognitive operations.</li>
											</ul>
											<img src="images/ML_Unit10_P3.png" alt="Visualization 1">
								                	<p></p>
											<img src="images/ML_Unit10_P4.png" alt="Visualization 2">
											<img src="images/ML_Unit10_P5.png" alt="Visualization 3">
							      		                <img src="images/ML_Unit10_P6.png" alt="Visualization 3">
											<p>The results show that:</p>
											<ol>
											    <li>By examining the feature maps produced by different layers (early layers, intermediate layers, and deeper layers), we can observe how the model processes and recognizes features at varying depths of the network.</li>
											    <li>Understanding of Feature Extraction: Early layers typically extract low-level features like edges and textures. This was evident in the visualizations of layer 1 and layer 2, where you observed different orientations and colour sensitivities. Intermediate and deeper layers capture higher-level features by combining the low-level features detected earlier. In the visuals of layer 3 and 4, the abstract patterns and broader activations reflect this.</li>
											    <li>By feeding different images through the network and visualizing their activations, you can understand how the network's recognition activities vary based on the input. This can be especially revealing when using images from categories the model was trained on versus those it wasn't.</li>
											</ol>
									

									       <h3 style="color: #CFA7F6;">Reflection & Practical Use:</h3>
								


											<p>Deep learning, particularly convolutional neural networks (CNNs), has revolutionised various sectors in today's data-driven world, from image identification to medical diagnosis. Mastering such strategies is critical for data scientists who want to stay on the cutting edge of innovation. However, even for seasoned specialists, the complexities of CNNs can provide steep learning curves.</p>
											<p>The emergence of technologies such as "CNN EXPLAINER" has the potential to revolutionise the game. It bridges the theoretical knowledge and practical application gap by providing interactive visual insights. Such technologies not only speed up the learning process for data scientists, but also help them better communicate complicated models to non-technical stakeholders.</p>
											<p>As the area of data science expands, tools that explain complicated algorithms will be critical in stimulating creativity. By making complex models more accessible, these tools can foster greater collaboration across disciplines and drive further innovation in the application of deep learning.</p>

									
									       <h3 style="color: #CFA7F6;">References:</h3>
									
											<ul>
											    <li>Wang, Z.J. et al. (2021) ‘CNN explainer: Learning convolutional neural networks with interactive visualization’, <i>IEEE Transactions on Visualization and Computer Graphics</i>, 27(2), pp. 1396–1406. doi:10.1109/tvcg.2020.3030418.</li>
											    <li>Chollet, F. (2021) <i>Deep learning with python</i>. Shelter Island, NY: Manning.</li>
											    <li>Ketkar, N. and Moolayil, J. (2021) <i>Deep learning with python</i> [Preprint]. doi:10.1007/978-1-4842-5364-9.</li>
											</ul>


							<p></p><a href="Unit 10 CNN Interactive Learning.ipynb" download>Click to download notebook for Unit 10 CNN Interactive Learning </a><p>  
									


									
								</div>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">

							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="js/jquery.min.js"></script>
			<script src="js/jquery.scrolly.min.js"></script>
			<script src="js/jquery.scrollex.min.js"></script>
			<script src="js/browser.min.js"></script>
			<script src="js/breakpoints.min.js"></script>
			<script src="js/util.js"></script>
			<script src="js/main.js"></script>

	</body>
</html>
